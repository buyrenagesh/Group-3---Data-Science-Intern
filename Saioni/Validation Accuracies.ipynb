{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------------Testing Accuracy on Validation Dataset---------------------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import unidecode\n",
    "#from wordcloud import WordCloud\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.animation as animation\n",
    "import operator\n",
    "#import plotly.express as px\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>Tweet_tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>last session day</td>\n",
       "      <td>['last', 'session', 'day']</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>shanghai also realli excit  precis    skyscrap...</td>\n",
       "      <td>['shanghai', 'also', 'realli', 'excit', 'preci...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>recess hit veroniqu branquinho  quit company  ...</td>\n",
       "      <td>['recess', 'hit', 'veroniqu', 'branquinho', 'q...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>happi bday</td>\n",
       "      <td>['happi', 'bday']</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I like it</td>\n",
       "      <td>['I', 'like', 'it']</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0           0                                  last session day    \n",
       "1           1  shanghai also realli excit  precis    skyscrap...   \n",
       "2           2  recess hit veroniqu branquinho  quit company  ...   \n",
       "3           3                                        happi bday    \n",
       "4           4                                        I like it     \n",
       "\n",
       "                                     Tweet_tokenized sentiment  \n",
       "0                         ['last', 'session', 'day']   neutral  \n",
       "1  ['shanghai', 'also', 'realli', 'excit', 'preci...   neutral  \n",
       "2  ['recess', 'hit', 'veroniqu', 'branquinho', 'q...   neutral  \n",
       "3                                  ['happi', 'bday']   neutral  \n",
       "4                                ['I', 'like', 'it']   neutral  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"logistic_regression.csv\")\n",
    "#data=data.drop('tokenized',axis=1)\n",
    "#data=data.drop('Unnamed: 0',axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3534, 4)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre - Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1766.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1020.322253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>883.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1766.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2649.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3533.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0\n",
       "count  3534.000000\n",
       "mean   1766.500000\n",
       "std    1020.322253\n",
       "min       0.000000\n",
       "25%     883.250000\n",
       "50%    1766.500000\n",
       "75%    2649.750000\n",
       "max    3533.000000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     last session day\n",
       "1    shanghai also realli excit precis skyscrap gal...\n",
       "2    recess hit veroniqu branquinho quit company shame\n",
       "3                                           happi bday\n",
       "4                                            i like it\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert to lower case\n",
    "data['text'] = data['text'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stopwards Removal\n",
    "data['text'] = data['text'].apply(lambda x : ' '.join([word for word in str(x).split() if not word in set(stopwords.words('english'))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data['text'] = data['text'].apply(lambda x : ' '.join([lemmatizer.lemmatize(word) for word in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     last session day\n",
       "1    shanghai also really exit precise skyscrap gal...\n",
       "2    recess hit veroniqu branquinho quit company shame\n",
       "3                                            happy day\n",
       "4                                                 like\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "data['text'][:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    tweet = re.sub('http://[A-Za-z0-9./]+','',tweet) \n",
    "    # remove special characters \n",
    "    tweet = re.sub('[^ a-zA-Z0-9]', '', tweet)\n",
    "    # remove Numbers\n",
    "    tweet = re.sub('[0-9]', '', tweet)\n",
    "    return tweet\n",
    "data['text'] = data['text'].apply(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>last session day httptwitpiccomezh</td>\n",
       "      <td>negative</td>\n",
       "      <td>[last, session, day, httptwitpiccomezh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>shanghai also realli excit precis skyscrap gal...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[shanghai, also, realli, excit, precis, skyscr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>recess hit veroniqu branquinho quit company shame</td>\n",
       "      <td>positive</td>\n",
       "      <td>[recess, hit, veroniqu, branquinho, quit, comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>happi bday</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[happi, bday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>httptwitpiccomwp like</td>\n",
       "      <td>positive</td>\n",
       "      <td>[httptwitpiccomwp, like]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text sentiment  \\\n",
       "0           0                 last session day httptwitpiccomezh  negative   \n",
       "1           1  shanghai also realli excit precis skyscrap gal...   neutral   \n",
       "2           2  recess hit veroniqu branquinho quit company shame  positive   \n",
       "3           3                                         happi bday   neutral   \n",
       "4           4                              httptwitpiccomwp like  positive   \n",
       "\n",
       "                                           tokenized  \n",
       "0            [last, session, day, httptwitpiccomezh]  \n",
       "1  [shanghai, also, realli, excit, precis, skyscr...  \n",
       "2  [recess, hit, veroniqu, branquinho, quit, comp...  \n",
       "3                                      [happi, bday]  \n",
       "4                           [httptwitpiccomwp, like]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "data['tokenized'] = data['text'].apply(tokenize)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction using TF-IDF Vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# create the transform\n",
    "cv = TfidfVectorizer(max_features=5000) \n",
    "x = cv.fit_transform(data['text'].tolist()).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "3       0.0\n",
      "4       0.0\n",
      "       ... \n",
      "3529    1.0\n",
      "3530    0.0\n",
      "3531    0.0\n",
      "3532    0.0\n",
      "3533    0.0\n",
      "Name: sentiment, Length: 3534, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data.sentiment[data.sentiment == 'positive'] = 1\n",
    "data.sentiment[data.sentiment == 'neutral'] = 0\n",
    "data.sentiment[data.sentiment == 'negative'] = 2\n",
    "y=data['sentiment'].astype('float')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import expon,uniform,randint\n",
    "\n",
    "#Sklearn imports\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV,cross_val_score,cross_val_predict,validation_curve\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0) #Basic train_test_split works here\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.99      0.91       710\n",
      "         1.0       0.88      0.30      0.45        69\n",
      "         2.0       0.72      0.17      0.28       105\n",
      "\n",
      "    accuracy                           0.84       884\n",
      "   macro avg       0.81      0.49      0.55       884\n",
      "weighted avg       0.83      0.84      0.80       884\n",
      "\n",
      "Accuracy : 0.8371040723981901 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "m = RandomForestClassifier(n_estimators=40, min_samples_leaf=3, n_jobs=-1)\n",
    "m.fit(x_train, y_train)\n",
    "predictions = m.predict(x_test)\n",
    "print(classification_report(y_test, predictions))\n",
    "print(\"Accuracy :\",accuracy_score(y_test, predictions),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8099547511312217\n",
      "[[709   0   1]\n",
      " [ 66   1   2]\n",
      " [ 99   0   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      1.00      0.90       710\n",
      "         1.0       1.00      0.01      0.03        69\n",
      "         2.0       0.67      0.06      0.11       105\n",
      "\n",
      "    accuracy                           0.81       884\n",
      "   macro avg       0.83      0.36      0.34       884\n",
      "weighted avg       0.81      0.81      0.73       884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With single train test split\n",
    "clf = LogisticRegression(solver='liblinear').fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8031674208144797\n",
      "[[710   0   0]\n",
      " [ 69   0   0]\n",
      " [105   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      1.00      0.89       710\n",
      "         1.0       0.00      0.00      0.00        69\n",
      "         2.0       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.80       884\n",
      "   macro avg       0.27      0.33      0.30       884\n",
      "weighted avg       0.65      0.80      0.72       884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Multinomial NB with single train test split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_model = MultinomialNB().fit(x_train, y_train)\n",
    "\n",
    "y_pred=nb_model.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
