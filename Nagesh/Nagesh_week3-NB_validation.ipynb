{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, precision_score,recall_score, f1_score, precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import ConditionalFreqDist\n",
    "from nltk.corpus import webtext\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "#COsine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.read_csv('NB_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3534, 2)\n",
      "7068\n"
     ]
    }
   ],
   "source": [
    "print(tweet_data.shape)\n",
    "print(tweet_data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session day</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai also really exciting precisely  skysc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recession hit veronique branquinho quit compan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>thats great weee visitors</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>think everyone hates lol</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>soooooo wish could im school myspace completel...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>within short time last clue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>get day alright havent done anything yet leavi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bike put holdshould known that argh total bummer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>checked didnt win</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>youre twitter tavern bore much</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>im va weekend youngest son turns  tomorrowit m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>coming socket feel like phones hole virgin tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  sentiment\n",
       "0                                   last session day           2\n",
       "1   shanghai also really exciting precisely  skysc...          1\n",
       "2   recession hit veronique branquinho quit compan...          0\n",
       "3                                          happy bday          2\n",
       "4                                             like it          1\n",
       "5                           thats great weee visitors          0\n",
       "6                            think everyone hates lol          0\n",
       "7   soooooo wish could im school myspace completel...          2\n",
       "8                         within short time last clue          0\n",
       "9   get day alright havent done anything yet leavi...          2\n",
       "10   bike put holdshould known that argh total bummer          0\n",
       "11                                  checked didnt win          0\n",
       "12                     youre twitter tavern bore much          0\n",
       "13  im va weekend youngest son turns  tomorrowit m...          0\n",
       "14  coming socket feel like phones hole virgin tha...          1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         3\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data=tweet_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3531, 2)\n",
      "7062\n"
     ]
    }
   ],
   "source": [
    "print(tweet_data.shape)\n",
    "print(tweet_data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a1abd90a20>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweet_data['sentiment'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 0, 1: 1, 0: 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapping categorical data to number\n",
    "def mapping_cat_to_num(col_name):\n",
    "    tweet_data[col_name].unique()\n",
    "    col_list = list(tweet_data[col_name].unique())\n",
    "    col_dict = {}\n",
    "    for i in range (len(col_list)):\n",
    "        col_dict[col_list[i]] = i\n",
    "    return col_dict\n",
    "\n",
    "\n",
    "clean_nums={}\n",
    "clean_nums =mapping_cat_to_num('sentiment')\n",
    "clean_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data.replace(clean_nums,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai also really exciting precisely  skysc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recession hit veronique branquinho quit compan...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0                                  last session day           0\n",
       "1  shanghai also really exciting precisely  skysc...          1\n",
       "2  recession hit veronique branquinho quit compan...          2\n",
       "3                                         happy bday          0\n",
       "4                                            like it          1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3529    2.0\n",
       "3530    0.0\n",
       "3531    2.0\n",
       "3532    2.0\n",
       "3533    0.0\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data['sentiment'].astype('float').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1928\n",
       "0     942\n",
       "1     661\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     last session day\n",
       "1    shanghai also really exciting precisely skyscr...\n",
       "2    recession hit veronique branquinho quit compan...\n",
       "3                                           happy bday\n",
       "4                                              like it\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data['text'] = tweet_data['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "tweet_data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords\n",
    "from nltk.corpus import stopwords\n",
    "tweet_data['text'] = tweet_data['text'].apply(lambda x : ' '.join([word for word in x.split() \n",
    "                                                                   if not word in set(stopwords.words('english'))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "#Citation: Borrowed a few regex'es from Google\n",
    "def process_tweets(text):\n",
    "    text = str(text).lower() #lower\n",
    "    text = re.sub('\\[.*?\\]', '', text) #Remove text in square brackets\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text) #Hyperlinks removal\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) #punctuations\n",
    "    text = re.sub('\\n', '', text) #newlines\n",
    "    text = re.sub('\\w*\\d\\w*', '', text) #word containing numbers\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-process the tweets\n",
    "tweet_data['text'] = tweet_data['text'].apply(lambda x:process_tweets(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3529                              im tired cant sleep try\n",
       "3530    alone old house thanks net keeps alive kicking...\n",
       "3531    know mean little dog sinking depression wants ...\n",
       "3532           sutra next youtube video gonna love videos\n",
       "3533                               omgssh ang cute ng bby\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data['text'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                 [last, session, day]\n",
      "1    [shanghai, also, realli, excit, precis, skyscr...\n",
      "2    [recess, hit, veroniqu, branquinho, quit, comp...\n",
      "3                                        [happi, bday]\n",
      "4                                               [like]\n",
      "Name: text, dtype: object\n",
      "3531\n"
     ]
    }
   ],
   "source": [
    "#Stemming\n",
    "stemmer = PorterStemmer()\n",
    "tokenized_tweet = tweet_data['text'].apply(lambda x: x.split()) \n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) \n",
    "print(tokenized_tweet.head())\n",
    "tweets_training_set = []\n",
    "for item in tokenized_tweet:\n",
    "    tweets_training_set.append(' '.join(item))\n",
    "print (len(tweets_training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai also really exciting precisely skyscr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recession hit veronique branquinho quit compan...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0                                   last session day          0\n",
       "1  shanghai also really exciting precisely skyscr...          1\n",
       "2  recession hit veronique branquinho quit compan...          2\n",
       "3                                         happy bday          0\n",
       "4                                               like          1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Analyzed_Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session day</td>\n",
       "      <td>0</td>\n",
       "      <td>last session day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai also really exciting precisely skyscr...</td>\n",
       "      <td>1</td>\n",
       "      <td>shanghai also realli excit precis skyscrap gal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recession hit veronique branquinho quit compan...</td>\n",
       "      <td>2</td>\n",
       "      <td>recess hit veroniqu branquinho quit compani shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>0</td>\n",
       "      <td>happi bday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>1</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  \\\n",
       "0                                   last session day          0   \n",
       "1  shanghai also really exciting precisely skyscr...          1   \n",
       "2  recession hit veronique branquinho quit compan...          2   \n",
       "3                                         happy bday          0   \n",
       "4                                               like          1   \n",
       "\n",
       "                                      Analyzed_Tweet  \n",
       "0                                   last session day  \n",
       "1  shanghai also realli excit precis skyscrap gal...  \n",
       "2  recess hit veroniqu branquinho quit compani shame  \n",
       "3                                         happi bday  \n",
       "4                                               like  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data['Analyzed_Tweet'] = tweets_training_set\n",
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3531 entries, 0 to 3533\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   text            3531 non-null   object\n",
      " 1   sentiment       3531 non-null   int64 \n",
      " 2   Analyzed_Tweet  3531 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 110.3+ KB\n"
     ]
    }
   ],
   "source": [
    "tweet_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      " 0.6181046676096181\n",
      "\n",
      "\n",
      "COnfusion Matrix\n",
      " [[ 48   0 137]\n",
      " [  4  11 120]\n",
      " [  9   0 378]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.26      0.39       185\n",
      "           1       1.00      0.08      0.15       135\n",
      "           2       0.60      0.98      0.74       387\n",
      "\n",
      "    accuracy                           0.62       707\n",
      "   macro avg       0.79      0.44      0.43       707\n",
      "weighted avg       0.72      0.62      0.54       707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TfTfidfVectorizer()\n",
    "TFIDF_vector = TfidfVectorizer(max_features=3000) \n",
    "X = TFIDF_vector.fit_transform(tweet_data['text'].tolist()).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, tweet_data['sentiment'], test_size = 0.20, random_state = 2)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n",
    "\n",
    "naive_bayes = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred=naive_bayes.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\\n\",accuracy_score(y_test, y_pred))\n",
    "print(\"\\n\\nCOnfusion Matrix\\n\",confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\\nClassification Report\\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      " 0.669024045261669\n",
      "\n",
      "\n",
      "COnfusion Matrix\n",
      " [[101  12  72]\n",
      " [ 18  49  68]\n",
      " [ 35  29 323]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.55      0.60       185\n",
      "           1       0.54      0.36      0.44       135\n",
      "           2       0.70      0.83      0.76       387\n",
      "\n",
      "    accuracy                           0.67       707\n",
      "   macro avg       0.63      0.58      0.60       707\n",
      "weighted avg       0.66      0.67      0.66       707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#changing the vector\n",
    "count_vector = CountVectorizer(max_features=3000) \n",
    "X = count_vector.fit_transform(tweet_data['text'].tolist()).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, tweet_data['sentiment'], test_size = 0.20, random_state = 2)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n",
    "\n",
    "naive_bayes = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred=naive_bayes.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\\n\",accuracy_score(y_test, y_pred))\n",
    "print(\"\\n\\nCOnfusion Matrix\\n\",confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\\nClassification Report\\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
