{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, precision_score,recall_score, f1_score, precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import ConditionalFreqDist\n",
    "from nltk.corpus import webtext\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "#COsine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-e396e556192a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclassifer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "classifer=nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweet_data.shape)\n",
    "print(tweet_data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tweet_data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data=tweet_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27447, 2)\n",
      "54894\n"
     ]
    }
   ],
   "source": [
    "print(tweet_data.shape)\n",
    "print(tweet_data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c3b69e65f8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweet_data['sentiment'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapping categorical data to number\n",
    "def mapping_cat_to_num(col_name):\n",
    "    tweet_data[col_name].unique()\n",
    "    col_list = list(tweet_data[col_name].unique())\n",
    "    col_dict = {}\n",
    "    for i in range (len(col_list)):\n",
    "        col_dict[col_list[i]] = i\n",
    "    return col_dict\n",
    "\n",
    "\n",
    "clean_nums={}\n",
    "clean_nums =mapping_cat_to_num('sentiment')\n",
    "clean_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data.replace(clean_nums,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh Marly, I`m so sorry!!  I hope you find her...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Playing Ghost Online is really interesting. Th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is cleaning the house for her family who is co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gotta restart my computer .. I thought Win7 wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEe waT I Mean bOuT FoLL0w fRiiDaYs... It`S cA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0   oh Marly, I`m so sorry!!  I hope you find her...          0\n",
       "1  Playing Ghost Online is really interesting. Th...          1\n",
       "2  is cleaning the house for her family who is co...          0\n",
       "3  gotta restart my computer .. I thought Win7 wa...          0\n",
       "4  SEe waT I Mean bOuT FoLL0w fRiiDaYs... It`S cA...          0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27443    2.0\n",
       "27444    2.0\n",
       "27445    1.0\n",
       "27446    0.0\n",
       "27447    1.0\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data['sentiment'].astype('float').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11105\n",
       "1     8575\n",
       "2     7767\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    oh marly, i`m so sorry!! i hope you find her s...\n",
       "1    playing ghost online is really interesting. th...\n",
       "2    is cleaning the house for her family who is co...\n",
       "3    gotta restart my computer .. i thought win7 wa...\n",
       "4    see wat i mean bout foll0w friidays... it`s ca...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data['text'] = tweet_data['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "tweet_data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords\n",
    "from nltk.corpus import stopwords\n",
    "tweet_data['text'] = tweet_data['text'].apply(lambda x : ' '.join([word for word in x.split() \n",
    "                                                                   if not word in set(stopwords.words('english'))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "#Citation: Borrowed a few regex'es from Google\n",
    "def process_tweets(text):\n",
    "    text = str(text).lower() #lower\n",
    "    text = re.sub('\\[.*?\\]', '', text) #Remove text in square brackets\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text) #Hyperlinks removal\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) #punctuations\n",
    "    text = re.sub('\\n', '', text) #newlines\n",
    "    text = re.sub('\\w*\\d\\w*', '', text) #word containing numbers\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-process the tweets\n",
    "tweet_data['text'] = tweet_data['text'].apply(lambda x:process_tweets(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27443    like drew said give tc chance miss thomas move...\n",
       "27444    rec gametrying crythe pain muchi need himcant ...\n",
       "27445          sure ill try n keep up p enjoy studying cya\n",
       "27446    naw pretty tame  guy costume voyagerstyle medi...\n",
       "27447            morning twitfriends welcome new followers\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data['text'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             [oh, marli, im, sorri, hope, find, soon]\n",
      "1    [play, ghost, onlin, realli, interest, new, up...\n",
      "2             [clean, hous, famili, com, later, today]\n",
      "3    [gotta, restart, comput, thought, suppos, put,...\n",
      "4    [see, wat, mean, bout, friiday, it, call, lose...\n",
      "Name: text, dtype: object\n",
      "27447\n"
     ]
    }
   ],
   "source": [
    "#Stemming\n",
    "stemmer = PorterStemmer()\n",
    "tokenized_tweet = tweet_data['text'].apply(lambda x: x.split()) \n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) \n",
    "print(tokenized_tweet.head())\n",
    "tweets_training_set = []\n",
    "for item in tokenized_tweet:\n",
    "    tweets_training_set.append(' '.join(item))\n",
    "print (len(tweets_training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh marly im sorry hope find soon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>playing ghost online really interesting new up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaning house family comming later today</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gotta restart computer  thought  supposed put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>see wat mean bout  friidays its called lose  f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0                 oh marly im sorry hope find soon            0\n",
       "1  playing ghost online really interesting new up...          1\n",
       "2          cleaning house family comming later today          0\n",
       "3  gotta restart computer  thought  supposed put ...          0\n",
       "4  see wat mean bout  friidays its called lose  f...          0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Analyzed_Tweet</th>\n",
       "      <th>Tokenized tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh marly im sorry hope find soon</td>\n",
       "      <td>0</td>\n",
       "      <td>oh marli im sorri hope find soon</td>\n",
       "      <td>[oh, marli, im, sorri, hope, find, soon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>playing ghost online really interesting new up...</td>\n",
       "      <td>1</td>\n",
       "      <td>play ghost onlin realli interest new updat kir...</td>\n",
       "      <td>[play, ghost, onlin, realli, interest, new, up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaning house family comming later today</td>\n",
       "      <td>0</td>\n",
       "      <td>clean hous famili com later today</td>\n",
       "      <td>[clean, hous, famili, com, later, today]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gotta restart computer  thought  supposed put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>gotta restart comput thought suppos put end co...</td>\n",
       "      <td>[gotta, restart, comput, thought, suppos, put,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>see wat mean bout  friidays its called lose  f...</td>\n",
       "      <td>0</td>\n",
       "      <td>see wat mean bout friiday it call lose friday smh</td>\n",
       "      <td>[see, wat, mean, bout, friiday, it, call, lose...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  \\\n",
       "0                 oh marly im sorry hope find soon            0   \n",
       "1  playing ghost online really interesting new up...          1   \n",
       "2          cleaning house family comming later today          0   \n",
       "3  gotta restart computer  thought  supposed put ...          0   \n",
       "4  see wat mean bout  friidays its called lose  f...          0   \n",
       "\n",
       "                                      Analyzed_Tweet  \\\n",
       "0                   oh marli im sorri hope find soon   \n",
       "1  play ghost onlin realli interest new updat kir...   \n",
       "2                  clean hous famili com later today   \n",
       "3  gotta restart comput thought suppos put end co...   \n",
       "4  see wat mean bout friiday it call lose friday smh   \n",
       "\n",
       "                                     Tokenized tweet  \n",
       "0           [oh, marli, im, sorri, hope, find, soon]  \n",
       "1  [play, ghost, onlin, realli, interest, new, up...  \n",
       "2           [clean, hous, famili, com, later, today]  \n",
       "3  [gotta, restart, comput, thought, suppos, put,...  \n",
       "4  [see, wat, mean, bout, friiday, it, call, lose...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data['Analyzed_Tweet'] = tweets_training_set\n",
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27447 entries, 0 to 27447\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   text             27447 non-null  object\n",
      " 1   sentiment        27447 non-null  int64 \n",
      " 2   Analyzed_Tweet   27447 non-null  object\n",
      " 3   Tokenized tweet  27447 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "tweet_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      " 0.6355191256830601\n",
      "\n",
      "\n",
      "COnfusion Matrix\n",
      " [[1710  283  200]\n",
      " [ 628 1029   64]\n",
      " [ 757   69  750]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.78      0.65      2193\n",
      "           1       0.75      0.60      0.66      1721\n",
      "           2       0.74      0.48      0.58      1576\n",
      "\n",
      "    accuracy                           0.64      5490\n",
      "   macro avg       0.68      0.62      0.63      5490\n",
      "weighted avg       0.67      0.64      0.63      5490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TfTfidfVectorizer()\n",
    "TFIDF_vector = TfidfVectorizer(max_features=3000) \n",
    "X = TFIDF_vector.fit_transform(tweet_data['text'].tolist()).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, tweet_data['sentiment'], test_size = 0.20, random_state = 2)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n",
    "\n",
    "naive_bayes = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred=naive_bayes.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\\n\",accuracy_score(y_test, y_pred))\n",
    "print(\"\\n\\nCOnfusion Matrix\\n\",confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\\nClassification Report\\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      " 0.6500910746812386\n",
      "\n",
      "\n",
      "COnfusion Matrix\n",
      " [[1509  360  324]\n",
      " [ 494 1136   91]\n",
      " [ 570   82  924]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.69      0.63      2193\n",
      "           1       0.72      0.66      0.69      1721\n",
      "           2       0.69      0.59      0.63      1576\n",
      "\n",
      "    accuracy                           0.65      5490\n",
      "   macro avg       0.67      0.64      0.65      5490\n",
      "weighted avg       0.66      0.65      0.65      5490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#changing the vector\n",
    "count_vector = CountVectorizer(max_features=3000) \n",
    "X = count_vector.fit_transform(tweet_data['text'].tolist()).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, tweet_data['sentiment'], test_size = 0.20, random_state = 2)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n",
    "\n",
    "naive_bayes = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred=naive_bayes.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\\n\",accuracy_score(y_test, y_pred))\n",
    "print(\"\\n\\nCOnfusion Matrix\\n\",confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\\nClassification Report\\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
