{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, precision_score,recall_score, f1_score, precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import ConditionalFreqDist\n",
    "from nltk.corpus import webtext\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "#COsine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.read_csv('train.csv')\n",
    "validation_data = pd.read_csv('E:/Ureka_Internship/Week-3/validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27448, 2) (3534, 1)\n",
      "54896 3534\n"
     ]
    }
   ],
   "source": [
    "print(tweet_data.shape, validation_data.shape)\n",
    "print(tweet_data.size, validation_data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh Marly, I`m so sorry!!  I hope you find her...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Playing Ghost Online is really interesting. Th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is cleaning the house for her family who is co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gotta restart my computer .. I thought Win7 wa...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEe waT I Mean bOuT FoLL0w fRiiDaYs... It`S cA...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0   oh Marly, I`m so sorry!!  I hope you find her...   neutral\n",
       "1  Playing Ghost Online is really interesting. Th...  positive\n",
       "2  is cleaning the house for her family who is co...   neutral\n",
       "3  gotta restart my computer .. I thought Win7 wa...   neutral\n",
       "4  SEe waT I Mean bOuT FoLL0w fRiiDaYs... It`S cA...   neutral"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Last session of the day  http://twitpic.com/67ezh\n",
       "1   Shanghai is also really exciting (precisely -...\n",
       "2  Recession hit Veronique Branquinho, she has to...\n",
       "3                                        happy bday!\n",
       "4             http://twitpic.com/4w75p - I like it!!"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         1\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data=tweet_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27447, 2) (3534, 1)\n",
      "54894 3534\n"
     ]
    }
   ],
   "source": [
    "print(tweet_data.shape, validation_data.shape)\n",
    "print(tweet_data.size, validation_data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fa417c2198>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD4CAYAAADy46FuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAATQklEQVR4nO3df5CdV33f8fenFgYjArJx2HEkJ3JATWJwSfCObUKbblDHliETeRq7FTWxTD2jJnUoUGdS0emMUxwyponjBreQKFixnKoxxqUjB5MYVbBpy9Q/wbH8A2ONrdrCLiaRbVgopKLf/nGPykWsjtC9q92V9X7N7OzznOec55zdPXo+9/lxr1JVSJJ0MH9joQcgSVrcDApJUpdBIUnqMigkSV0GhSSpa8lCD2BUJ598cq1cuXKktl//+tdZunTp3A5IapxfOpLGmV/33nvvX1bVDx5uu6M2KFauXMk999wzUtvp6WmmpqbmdkBS4/zSkTTO/EryP0dp56UnSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklS11H7zuxx7PzS81y68bZ573f31W+d9z4laVyeUUiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1HXIoEiyOckzSR4YKjspyfYkj7bvJ7byJPlgkl1J7k/yhqE261v9R5OsHyo/M8nO1uaDSTLXP6QkaXTfzxnFDcCaA8o2AjuqahWwo60DnA+sal8bgA/DIFiAK4GzgbOAK/eHS6uzYajdgX1JkhbQIYOiqv4rsPeA4rXAlra8BbhgqPzGGrgDWJbkFOA8YHtV7a2qZ4HtwJq27eVV9T+qqoAbh/YlSVoERv0/syeq6mmAqno6yata+XLgyaF6e1pZr3zPLOWzSrKBwdkHExMTTE9Pjzb4E+CKM/aN1HYco45XR5eZmRn/1jpiFmJ+jRoUBzPb/YUaoXxWVbUJ2AQwOTlZU1NTIwwRrtu6jWt2zvWPfmi7L56a9z41/6anpxl1bkqHshDza9Snnr7cLhvRvj/TyvcApw7VWwE8dYjyFbOUS5IWiVGD4lZg/5NL64FtQ+WXtKefzgGeb5eobgfOTXJiu4l9LnB72/a1JOe0p50uGdqXJGkROOT1lyR/DEwBJyfZw+DppauBm5NcBjwBXNSqfxJ4C7AL+AbwDoCq2pvkKuDuVu99VbX/BvkvM3iy6gTgT9uXJGmROGRQVNXbDrJp9Sx1C7j8IPvZDGyepfwe4HWHGockaWH4zmxJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdS1Z6AFILzQ7v/Q8l268bd773X31W+e9Tx0bPKOQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6horKJK8J8mDSR5I8sdJXpLktCR3Jnk0yUeTHN/qvrit72rbVw7t572t/JEk5433I0mS5tLIQZFkOfDPgMmqeh1wHLAO+ABwbVWtAp4FLmtNLgOerarXANe2eiQ5vbV7LbAG+FCS40YdlyRpbo176WkJcEKSJcBLgaeBNwO3tO1bgAva8tq2Ttu+Okla+U1V9a2qehzYBZw15rgkSXNk5KCoqi8Bvw08wSAgngfuBZ6rqn2t2h5geVteDjzZ2u5r9V85XD5LG0nSAhv5IzySnMjgbOA04DngY8D5s1St/U0Osu1g5bP1uQHYADAxMcH09PThDbqZOAGuOGPfoSvOsVHHq6OL80tH0szMzLz/rcf5rKe/BzxeVV8BSPJx4KeBZUmWtLOGFcBTrf4e4FRgT7tU9Qpg71D5fsNtvktVbQI2AUxOTtbU1NRIA79u6zau2Tn/H3O1++Kpee9T88/5pSNpenqaUY99oxrnHsUTwDlJXtruNawGHgI+A1zY6qwHtrXlW9s6bfunq6pa+br2VNRpwCrgrjHGJUmaQyO/7KmqO5PcAnwO2Ad8nsGr/duAm5L8Riu7vjW5HvijJLsYnEmsa/t5MMnNDEJmH3B5VX171HFJkubWWOfHVXUlcOUBxY8xy1NLVfVN4KKD7Of9wPvHGYskzaeVC/BR8gA3rFk67336zmxJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHWNFRRJliW5JckXkjyc5I1JTkqyPcmj7fuJrW6SfDDJriT3J3nD0H7Wt/qPJlk/7g8lSZo7455R/C7wZ1X148DrgYeBjcCOqloF7GjrAOcDq9rXBuDDAElOAq4EzgbOAq7cHy6SpIU3clAkeTnwM8D1AFX111X1HLAW2NKqbQEuaMtrgRtr4A5gWZJTgPOA7VW1t6qeBbYDa0YdlyRpbi0Zo+2PAl8B/jDJ64F7gXcBE1X1NEBVPZ3kVa3+cuDJofZ7WtnByr9Hkg0MzkaYmJhgenp6pIFPnABXnLFvpLbjGHW8Oro4v44NC/E3BpiZmZn3v/U4QbEEeAPwzqq6M8nv8p3LTLPJLGXVKf/ewqpNwCaAycnJmpqaOqwB73fd1m1cs3OcH300uy+emvc+Nf+cX8eGSzfetiD93rBmKaMe+0Y1zj2KPcCeqrqzrd/CIDi+3C4p0b4/M1T/1KH2K4CnOuWSpEVg5KCoqv8FPJnkx1rRauAh4FZg/5NL64FtbflW4JL29NM5wPPtEtXtwLlJTmw3sc9tZZKkRWDc8+N3AluTHA88BryDQfjcnOQy4Angolb3k8BbgF3AN1pdqmpvkquAu1u991XV3jHHJUmaI2MFRVXdB0zOsmn1LHULuPwg+9kMbB5nLJKkI8N3ZkuSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldYwdFkuOSfD7JJ9r6aUnuTPJoko8mOb6Vv7it72rbVw7t472t/JEk5407JknS3JmLM4p3AQ8PrX8AuLaqVgHPApe18suAZ6vqNcC1rR5JTgfWAa8F1gAfSnLcHIxLkjQHxgqKJCuAtwIfaesB3gzc0qpsAS5oy2vbOm376lZ/LXBTVX2rqh4HdgFnjTMuSdLcWTJm+38L/BrwA239lcBzVbWvre8Blrfl5cCTAFW1L8nzrf5y4I6hfQ63+S5JNgAbACYmJpienh5p0BMnwBVn7Dt0xTk26nh1dHF+HRsW4m8MMDMzM+9/65GDIsnPAc9U1b1JpvYXz1K1DrGt1+a7C6s2AZsAJicna2pqarZqh3Td1m1cs3PcjDx8uy+emvc+Nf+cX8eGSzfetiD93rBmKaMe+0Y1zmx+E/DzSd4CvAR4OYMzjGVJlrSzihXAU63+HuBUYE+SJcArgL1D5fsNt5EkLbCR71FU1XurakVVrWRwM/rTVXUx8BngwlZtPbCtLd/a1mnbP11V1crXtaeiTgNWAXeNOi5J0tw6EufH/wK4KclvAJ8Hrm/l1wN/lGQXgzOJdQBV9WCSm4GHgH3A5VX17SMwLknSCOYkKKpqGphuy48xy1NLVfVN4KKDtH8/8P65GIskaW75zmxJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpa+SgSHJqks8keTjJg0ne1cpPSrI9yaPt+4mtPEk+mGRXkvuTvGFoX+tb/UeTrB//x5IkzZVxzij2AVdU1U8A5wCXJzkd2AjsqKpVwI62DnA+sKp9bQA+DINgAa4EzgbOAq7cHy6SpIU3clBU1dNV9bm2/DXgYWA5sBbY0qptAS5oy2uBG2vgDmBZklOA84DtVbW3qp4FtgNrRh2XJGluzck9iiQrgZ8C7gQmquppGIQJ8KpWbTnw5FCzPa3sYOWSpEVgybg7SPIy4D8B766qryY5aNVZyqpTPltfGxhctmJiYoLp6enDHi/AxAlwxRn7Rmo7jlHHq6OL8+vYsBB/Y4CZmZl5/1uPFRRJXsQgJLZW1cdb8ZeTnFJVT7dLS8+08j3AqUPNVwBPtfKpA8qnZ+uvqjYBmwAmJydrampqtmqHdN3WbVyzc+yMPGy7L56a9z41/5xfx4ZLN962IP3esGYpox77RjXOU08BrgcerqrfGdp0K7D/yaX1wLah8kva00/nAM+3S1O3A+cmObHdxD63lUmSFoFxXva8CfhFYGeS+1rZvwSuBm5OchnwBHBR2/ZJ4C3ALuAbwDsAqmpvkquAu1u991XV3jHGJUmaQyMHRVX9d2a/vwCwepb6BVx+kH1tBjaPOhZJ0pHjO7MlSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktS1aIIiyZokjyTZlWTjQo9HkjSwKIIiyXHAvwfOB04H3pbk9IUdlSQJFklQAGcBu6rqsar6a+AmYO0Cj0mSBCxZ6AE0y4Enh9b3AGcfWCnJBmBDW51J8siI/Z0M/OWIbUeWD8x3j1ogzi8dMT/7gbHm14+M0mixBEVmKavvKajaBGwau7PknqqaHHc/0mycXzqSFmJ+LZZLT3uAU4fWVwBPLdBYJElDFktQ3A2sSnJakuOBdcCtCzwmSRKL5NJTVe1L8ivA7cBxwOaqevAIdjn25Supw/mlI2ne51eqvudWgCRJ/99iufQkSVqkDApJUtcxGxRJVib5RyO2nZnr8ejol+SXklzSli9N8kND2z7ipw1oriVZluSfDq3/UJJb5ryfY/UeRZIp4Fer6udm2bakqvZ12s5U1cuO5Ph0dEsyzWB+3bPQY9ELV5KVwCeq6nVHsp+j7oyinQk8nOQPkjyY5FNJTkjy6iR/luTeJP8tyY+3+jckuXCo/f6zgauBv5PkviTvaa8AP5bkT4BPJXlZkh1JPpdkZxI/UuQFrM2rLyTZkuT+JLckeWmS1Uk+3+bA5iQvbvWvTvJQq/vbrezXk/xqm2+TwNY2v05IMp1kMskvJ/k3Q/1emuS6tvz2JHe1Nr/fPgNNR7ERjlevTnJHkruTvG//8apzPLoaeHWbM7/V+nugtbkzyWuHxjKd5MwkS9tcvrvN7UMf26rqqPoCVgL7gJ9s6zcDbwd2AKta2dnAp9vyDcCFQ+1n2vcpBkm8v/xSBm/8O6mtLwFe3pZPBnbxnTOwmYX+Pfh1ROZVAW9q65uBf8Xgo2X+Ziu7EXg3cBLwyNB8WNa+/zqDswiAaWByaP/TDMLjBxl8rtn+8j8F/jbwE8CfAC9q5R8CLlno34tfczKvDud49QngbW35l4aOV7Mej9r+Hzigvwfa8nuAf92WTwG+2JZ/E3h7W14GfBFY2vs5jroziubxqrqvLd/L4Jfz08DHktwH/D6DX8zh2l5Ve9tygN9Mcj/wXxh8HtXEWKPWYvdkVX22Lf8HYDWDufbFVrYF+Bngq8A3gY8k+fvAN77fDqrqK8BjSc5J8krgx4DPtr7OBO5uc3g18KNz8DNp4R3O8eqNwMfa8n8c2scox6ObgYva8j8Y2u+5wMbW9zTwEuCHeztaFG+4G8G3hpa/zeAX9lxV/eQsdffRLrElCXB8Z79fH1q+mMGrvzOr6v8k2c3gF6oXru/rhl0N3iB6FoOD+TrgV4A3H0Y/H2XwD/cLwH+uqmpzc0tVvfcwx6zF73COVwdz2MejqvpSkr9K8reAfwj8k7YpwC9U1ff9oapH6xnFgb4KPJ7kIhgEQpLXt227GbxSg8FHl7+oLX8N+IHOPl8BPNP+KD/LiJ+6qKPKDyd5Y1t+G4NXbiuTvKaV/SLw50leBryiqj7J4FLUbP/ge/Pr48AFrY+PtrIdwIVJXgWQ5KQkzrkXpt7x6g7gF9ryuqE2BzseHeo4dhPwawzm685WdjvwzvbihCQ/dagBv1CCAgaJe1mSvwAe5Dv/n8UfAH83yV0MrgXuP2u4H9iX5C+SvGeW/W0FJpPc0/b9hSM6ei0GDwPr2+n9ScC1wDsYXCLYCfxf4PcY/MP8RKv35wyuBR/oBuD39t/MHt5QVc8CDwE/UlV3tbKHGNwT+VTb73ZGu3yqo8PBjlfvBv55O16dAjzfymc9HlXVXwGfTfJAkt+apZ9bGATOzUNlVzF4wXx/u/F91aEGe8w+HisNyzw9Zij1JHkp8L/b5ch1DG5sL/gTl0frPQpJeiE6E/h37bLQc8A/XuDxAJ5RSJIO4YV0j0KSdAQYFJKkLoNCktRlUEiSugwKSVLX/wNmecEMorQCbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweet_data['sentiment'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 0, 'positive': 1, 'negative': 2}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapping categorical data to number\n",
    "def mapping_cat_to_num(col_name):\n",
    "    tweet_data[col_name].unique()\n",
    "    col_list = list(tweet_data[col_name].unique())\n",
    "    col_dict = {}\n",
    "    for i in range (len(col_list)):\n",
    "        col_dict[col_list[i]] = i\n",
    "    return col_dict\n",
    "\n",
    "\n",
    "clean_nums={}\n",
    "clean_nums =mapping_cat_to_num('sentiment')\n",
    "clean_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data.replace(clean_nums,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh Marly, I`m so sorry!!  I hope you find her...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Playing Ghost Online is really interesting. Th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is cleaning the house for her family who is co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gotta restart my computer .. I thought Win7 wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEe waT I Mean bOuT FoLL0w fRiiDaYs... It`S cA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0   oh Marly, I`m so sorry!!  I hope you find her...          0\n",
       "1  Playing Ghost Online is really interesting. Th...          1\n",
       "2  is cleaning the house for her family who is co...          0\n",
       "3  gotta restart my computer .. I thought Win7 wa...          0\n",
       "4  SEe waT I Mean bOuT FoLL0w fRiiDaYs... It`S cA...          0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27443    2.0\n",
       "27444    2.0\n",
       "27445    1.0\n",
       "27446    0.0\n",
       "27447    1.0\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data['sentiment'].astype('float').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11105\n",
       "1     8575\n",
       "2     7767\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    oh marly, i`m so sorry!! i hope you find her s...\n",
      "1    playing ghost online is really interesting. th...\n",
      "2    is cleaning the house for her family who is co...\n",
      "3    gotta restart my computer .. i thought win7 wa...\n",
      "4    see wat i mean bout foll0w friidays... it`s ca...\n",
      "Name: text, dtype: object\n",
      "0     last session of the day http://twitpic.com/67ezh\n",
      "1    shanghai is also really exciting (precisely --...\n",
      "2    recession hit veronique branquinho, she has to...\n",
      "3                                          happy bday!\n",
      "4               http://twitpic.com/4w75p - i like it!!\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "tweet_data['text'] = tweet_data['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "print(tweet_data['text'].head())\n",
    "\n",
    "validation_data['text'] = validation_data['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "print(validation_data['text'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords\n",
    "from nltk.corpus import stopwords\n",
    "tweet_data['text'] = tweet_data['text'].apply(lambda x : ' '.join([word for word in x.split() \n",
    "                                                                   if not word in set(stopwords.words('english'))]))\n",
    "\n",
    "validation_data['text'] = validation_data['text'].apply(lambda x : ' '.join([word for word in x.split() \n",
    "                                                                   if not word in set(stopwords.words('english'))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "#Citation: Borrowed a few regex'es from Google\n",
    "def process_tweets(text):\n",
    "    text = str(text).lower() #lower\n",
    "    text = re.sub('\\[.*?\\]', '', text) #Remove text in square brackets\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text) #Hyperlinks removal\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) #punctuations\n",
    "    text = re.sub('\\n', '', text) #newlines\n",
    "    text = re.sub('\\w*\\d\\w*', '', text) #word containing numbers\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-process the tweets\n",
    "tweet_data['text'] = tweet_data['text'].apply(lambda x:process_tweets(x))\n",
    "validation_data['text'] = validation_data['text'].apply(lambda x:process_tweets(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                   oh marly im sorry hope find soon  \n",
      "1    playing ghost online really interesting new up...\n",
      "2            cleaning house family comming later today\n",
      "3    gotta restart computer  thought  supposed put ...\n",
      "4    see wat mean bout  friidays its called lose  f...\n",
      "Name: text, dtype: object\n",
      "\n",
      " 0                                    last session day \n",
      "1    shanghai also really exciting precisely  skysc...\n",
      "2    recession hit veronique branquinho quit compan...\n",
      "3                                           happy bday\n",
      "4                                              like it\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(tweet_data['text'].head())\n",
    "print(\"\\n\",validation_data['text'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             [oh, marli, im, sorri, hope, find, soon]\n",
      "1    [play, ghost, onlin, realli, interest, new, up...\n",
      "2             [clean, hous, famili, com, later, today]\n",
      "3    [gotta, restart, comput, thought, suppos, put,...\n",
      "4    [see, wat, mean, bout, friiday, it, call, lose...\n",
      "Name: text, dtype: object\n",
      "27447\n"
     ]
    }
   ],
   "source": [
    "#Stemming\n",
    "stemmer = PorterStemmer()\n",
    "tokenized_tweet = tweet_data['text'].apply(lambda x: x.split()) \n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) \n",
    "print(tokenized_tweet.head())\n",
    "tweets_training_set = []\n",
    "for item in tokenized_tweet:\n",
    "    tweets_training_set.append(' '.join(item))\n",
    "print (len(tweets_training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh marly im sorry hope find soon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>playing ghost online really interesting new up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaning house family comming later today</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gotta restart computer  thought  supposed put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>see wat mean bout  friidays its called lose  f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0                 oh marly im sorry hope find soon            0\n",
       "1  playing ghost online really interesting new up...          1\n",
       "2          cleaning house family comming later today          0\n",
       "3  gotta restart computer  thought  supposed put ...          0\n",
       "4  see wat mean bout  friidays its called lose  f...          0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Analyzed_Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh marly im sorry hope find soon</td>\n",
       "      <td>0</td>\n",
       "      <td>oh marli im sorri hope find soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>playing ghost online really interesting new up...</td>\n",
       "      <td>1</td>\n",
       "      <td>play ghost onlin realli interest new updat kir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaning house family comming later today</td>\n",
       "      <td>0</td>\n",
       "      <td>clean hous famili com later today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gotta restart computer  thought  supposed put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>gotta restart comput thought suppos put end co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>see wat mean bout  friidays its called lose  f...</td>\n",
       "      <td>0</td>\n",
       "      <td>see wat mean bout friiday it call lose friday smh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  \\\n",
       "0                 oh marly im sorry hope find soon            0   \n",
       "1  playing ghost online really interesting new up...          1   \n",
       "2          cleaning house family comming later today          0   \n",
       "3  gotta restart computer  thought  supposed put ...          0   \n",
       "4  see wat mean bout  friidays its called lose  f...          0   \n",
       "\n",
       "                                      Analyzed_Tweet  \n",
       "0                   oh marli im sorri hope find soon  \n",
       "1  play ghost onlin realli interest new updat kir...  \n",
       "2                  clean hous famili com later today  \n",
       "3  gotta restart comput thought suppos put end co...  \n",
       "4  see wat mean bout friiday it call lose friday smh  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data['Analyzed_Tweet'] = tweets_training_set\n",
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27447 entries, 0 to 27447\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   text            27447 non-null  object\n",
      " 1   sentiment       27447 non-null  int64 \n",
      " 2   Analyzed_Tweet  27447 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 857.7+ KB\n"
     ]
    }
   ],
   "source": [
    "tweet_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      " 0.6400728597449908\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      " [[1731  267  195]\n",
      " [ 637 1025   59]\n",
      " [ 749   69  758]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.79      0.65      2193\n",
      "           1       0.75      0.60      0.67      1721\n",
      "           2       0.75      0.48      0.59      1576\n",
      "\n",
      "    accuracy                           0.64      5490\n",
      "   macro avg       0.69      0.62      0.63      5490\n",
      "weighted avg       0.67      0.64      0.64      5490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TfTfidfVectorizer()\n",
    "TFIDF_vector = TfidfVectorizer(max_features=2000) \n",
    "X = TFIDF_vector.fit_transform(tweet_data['text'].tolist()).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, tweet_data['sentiment'], test_size = 0.20, random_state = 2)\n",
    "\n",
    "x_val = TFIDF_vector.fit_transform(validation_data['text'].tolist()).toarray()\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n",
    "\n",
    "naive_bayes = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred=naive_bayes.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\\n\",accuracy_score(y_test, y_pred))\n",
    "print(\"\\n\\nConfusion Matrix\\n\",confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\\nClassification Report\\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session day</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai also really exciting precisely  skysc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recession hit veronique branquinho quit compan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0                                  last session day           2\n",
       "1  shanghai also really exciting precisely  skysc...          1\n",
       "2  recession hit veronique branquinho quit compan...          0\n",
       "3                                         happy bday          2\n",
       "4                                            like it          1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle  \n",
    "# Save the trained model as a pickle string. \n",
    "saved_model = pickle.dumps(naive_bayes) \n",
    "  \n",
    "# Load the pickled model \n",
    "rf_from_pickle = pickle.loads(saved_model) \n",
    "  \n",
    "# Use the loaded pickled model to make predictions \n",
    "NB_y_pred=rf_from_pickle.predict(x_val) \n",
    "NB_y_pred\n",
    "\n",
    "NB_validation = pd.DataFrame({'text':validation_data['text'],'sentiment':NB_y_pred})\n",
    "NB_validation = NB_validation[['text','sentiment']]\n",
    "NB_validation.to_csv(\"NB_validation.csv\",index = False)\n",
    "NB_df=pd.read_csv('NB_validation.csv')\n",
    "NB_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      " 0.6517304189435337\n",
      "\n",
      "\n",
      "COnfusion Matrix\n",
      " [[1536  347  310]\n",
      " [ 504 1124   93]\n",
      " [ 578   80  918]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.70      0.64      2193\n",
      "           1       0.72      0.65      0.69      1721\n",
      "           2       0.69      0.58      0.63      1576\n",
      "\n",
      "    accuracy                           0.65      5490\n",
      "   macro avg       0.67      0.65      0.65      5490\n",
      "weighted avg       0.66      0.65      0.65      5490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#changing the vector\n",
    "count_vector = CountVectorizer(max_features=2000) \n",
    "X = count_vector.fit_transform(tweet_data['text'].tolist()).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, tweet_data['sentiment'], test_size = 0.20, random_state = 2)\n",
    "\n",
    "x_val = TFIDF_vector.fit_transform(validation_data['text'].tolist()).toarray()\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n",
    "\n",
    "naive_bayes = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred=naive_bayes.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\\n\",accuracy_score(y_test, y_pred))\n",
    "print(\"\\n\\nCOnfusion Matrix\\n\",confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\\nClassification Report\\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session day</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai also really exciting precisely  skysc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recession hit veronique branquinho quit compan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0                                  last session day           2\n",
       "1  shanghai also really exciting precisely  skysc...          1\n",
       "2  recession hit veronique branquinho quit compan...          0\n",
       "3                                         happy bday          2\n",
       "4                                            like it          1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle  \n",
    "# Save the trained model as a pickle string. \n",
    "saved_model = pickle.dumps(naive_bayes) \n",
    "  \n",
    "# Load the pickled model \n",
    "rf_from_pickle = pickle.loads(saved_model) \n",
    "  \n",
    "# Use the loaded pickled model to make predictions \n",
    "NB_y_pred=rf_from_pickle.predict(x_val) \n",
    "NB_y_pred\n",
    "\n",
    "NB_validation = pd.DataFrame({'text':validation_data['text'],'sentiment':NB_y_pred})\n",
    "NB_validation = NB_validation[['text','sentiment']]\n",
    "NB_validation.to_csv(\"NB_validation_counter.csv\",index = False)\n",
    "NB_df=pd.read_csv('NB_validation_counter.csv')\n",
    "NB_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\buyre\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\buyre\\anaconda3\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\buyre\\anaconda3\\lib\\site-packages (from xgboost) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='binary:logistic', random_state=None, reg_alpha=None,\n",
       "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "              tree_method=None, validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      " 0.6836065573770492\n",
      "\n",
      "\n",
      "COnfusion Matrix\n",
      " [[1781  250  162]\n",
      " [ 495 1169   57]\n",
      " [ 684   89  803]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.81      0.69      2193\n",
      "           1       0.78      0.68      0.72      1721\n",
      "           2       0.79      0.51      0.62      1576\n",
      "\n",
      "    accuracy                           0.68      5490\n",
      "   macro avg       0.72      0.67      0.68      5490\n",
      "weighted avg       0.71      0.68      0.68      5490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#changing the vector\n",
    "count_vector = CountVectorizer(max_features=2000) \n",
    "X = count_vector.fit_transform(tweet_data['text'].tolist()).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, tweet_data['sentiment'], test_size = 0.20, random_state = 2)\n",
    "\n",
    "x_val = TFIDF_vector.fit_transform(validation_data['text'].tolist()).toarray()\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n",
    "\n",
    "xgb = XGBClassifier().fit(X_train, y_train)\n",
    "\n",
    "y_pred=xgb.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\\n\",accuracy_score(y_test, y_pred))\n",
    "print(\"\\n\\nCOnfusion Matrix\\n\",confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\\nClassification Report\\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-c635a3df7c1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Use the loaded pickled model to make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrf_from_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mxgb_y_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mxgb_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mxgb_y_pred\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb_y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle  \n",
    "# Save the trained model as a pickle string. \n",
    "saved_model = pickle.dumps(naive_bayes) \n",
    "  \n",
    "# Load the pickled model \n",
    "rf_from_pickle = pickle.loads(saved_model) \n",
    "  \n",
    "# Use the loaded pickled model to make predictions \n",
    "xgb=rf_from_pickle.predict(x_val) \n",
    "xgb_y_pred\n",
    "\n",
    "xgb_validation = pd.DataFrame({'text':validation_data['text'],'sentiment':xgb_y_pred})\n",
    "xgb_validation = xgb_validation[['text','sentiment']]\n",
    "xgb_validation.to_csv(\"xgb_validation_counter.csv\",index = False)\n",
    "xgb_df=pd.read_csv('xgb_validation_counter.csv')\n",
    "xgb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
